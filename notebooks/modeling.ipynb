{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb180ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer  # Added this import\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (roc_auc_score, average_precision_score, f1_score, \n",
    "                            classification_report, confusion_matrix)\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48571a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Load and preprocess data\n",
    "def load_and_preprocess_data(file_path):\n",
    "    # Load the data\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Print initial info\n",
    "    print(\"Initial data shape:\", df.shape)\n",
    "    print(\"\\nColumns in the dataset:\")\n",
    "    print(df.columns.tolist())\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(\"\\nMissing values per column:\")\n",
    "    print(df.isnull().sum())\n",
    "    \n",
    "    # Check for target variable\n",
    "    target_col = None\n",
    "    for col in ['class', 'Class']:\n",
    "        if col in df.columns:\n",
    "            target_col = col\n",
    "            break\n",
    "    \n",
    "    if not target_col:\n",
    "        raise ValueError(\"No target column ('class' or 'Class') found in the dataset\")\n",
    "    \n",
    "    print(f\"\\nUsing '{target_col}' as the target variable\")\n",
    "    \n",
    "    # Convert target to numeric, coerce errors to NaN\n",
    "    df[target_col] = pd.to_numeric(df[target_col], errors='coerce')\n",
    "    \n",
    "    # Drop rows where target is NaN\n",
    "    initial_rows = len(df)\n",
    "    df = df.dropna(subset=[target_col])\n",
    "    dropped_rows = initial_rows - len(df)\n",
    "    print(f\"\\nDropped {dropped_rows} rows with NaN in target column\")\n",
    "    \n",
    "    # Convert target to int (0 and 1)\n",
    "    df[target_col] = df[target_col].astype(int)\n",
    "    \n",
    "    # Check class distribution\n",
    "    print(\"\\nClass distribution after cleaning:\")\n",
    "    print(df[target_col].value_counts(normalize=True).mul(100).round(2))\n",
    "    \n",
    "    # Convert datetime columns if they exist\n",
    "    datetime_cols = ['signup_time', 'purchase_time']\n",
    "    for col in datetime_cols:\n",
    "        if col in df.columns:\n",
    "            print(f\"\\nProcessing datetime column: {col}\")\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            # Extract useful datetime features\n",
    "            df[f'{col}_hour'] = df[col].dt.hour\n",
    "            df[f'{col}_dayofweek'] = df[col].dt.dayofweek\n",
    "            df[f'{col}_dayofmonth'] = df[col].dt.day\n",
    "            df[f'{col}_month'] = df[col].dt.month\n",
    "    \n",
    "    # Drop original datetime columns and any other non-numeric columns that might cause issues\n",
    "    cols_to_drop = datetime_cols + [col for col in df.columns if df[col].dtype == 'object' and col != target_col]\n",
    "    df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "    \n",
    "    # Check for any remaining non-numeric columns\n",
    "    non_numeric_cols = [col for col in df.columns if df[col].dtype == 'object' and col != target_col]\n",
    "    if non_numeric_cols:\n",
    "        print(f\"\\nWarning: Found non-numeric columns that will be dropped: {non_numeric_cols}\")\n",
    "        df = df.drop(columns=non_numeric_cols)\n",
    "    \n",
    "    # Fill any remaining NaN values with median for numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns.difference([target_col])\n",
    "    if df[numeric_cols].isnull().any().any():\n",
    "        print(\"\\nFilling remaining NaN values with median...\")\n",
    "        df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df.drop(target_col, axis=1)\n",
    "    y = df[target_col]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed34e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Load the data\n",
    "data_paths = [\n",
    "    '../data/processed/fraud_processed.csv',\n",
    "    '../data/rw/Fraud_Data.csv',\n",
    "    '../data/raw/creditcard.csv'\n",
    "]\n",
    "X, y = None, None\n",
    "for path in data_paths:\n",
    "    try:\n",
    "        print(f\"\\nTrying to load data from: {path}\")\n",
    "        X, y = load_and_preprocess_data(path)\n",
    "        print(f\"Successfully loaded data from {path}\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {path}: {str(e)}\")\n",
    "if X is None or y is None:\n",
    "    raise FileNotFoundError(\"Could not load any of the data files. Please check the file paths.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "264dcdcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns: ['user_id', 'purchase_value', 'age', 'lower_bound_ip_address', 'upper_bound_ip_address', 'time_since_signup', 'hour_of_day', 'day_of_week', 'user_transaction_count', 'time_since_last_txn', 'txn_within_1hr']\n",
      "Categorical columns: ['source_Direct', 'source_SEO', 'browser_FireFox', 'browser_IE', 'browser_Opera', 'browser_Safari', 'sex_M', 'country_Albania', 'country_Algeria', 'country_Angola', 'country_Antigua and Barbuda', 'country_Argentina', 'country_Armenia', 'country_Australia', 'country_Austria', 'country_Azerbaijan', 'country_Bahamas', 'country_Bahrain', 'country_Bangladesh', 'country_Barbados', 'country_Belarus', 'country_Belgium', 'country_Belize', 'country_Benin', 'country_Bermuda', 'country_Bhutan', 'country_Bolivia', 'country_Bonaire; Sint Eustatius; Saba', 'country_Bosnia and Herzegowina', 'country_Botswana', 'country_Brazil', 'country_British Indian Ocean Territory', 'country_Brunei Darussalam', 'country_Bulgaria', 'country_Burkina Faso', 'country_Burundi', 'country_Cambodia', 'country_Cameroon', 'country_Canada', 'country_Cape Verde', 'country_Cayman Islands', 'country_Chile', 'country_China', 'country_Colombia', 'country_Congo', 'country_Congo The Democratic Republic of The', 'country_Costa Rica', \"country_Cote D'ivoire\", 'country_Croatia (LOCAL Name: Hrvatska)', 'country_Cuba', 'country_Curacao', 'country_Cyprus', 'country_Czech Republic', 'country_Denmark', 'country_Djibouti', 'country_Dominica', 'country_Dominican Republic', 'country_Ecuador', 'country_Egypt', 'country_El Salvador', 'country_Estonia', 'country_Ethiopia', 'country_European Union', 'country_Faroe Islands', 'country_Fiji', 'country_Finland', 'country_France', 'country_Gabon', 'country_Gambia', 'country_Georgia', 'country_Germany', 'country_Ghana', 'country_Gibraltar', 'country_Greece', 'country_Guadeloupe', 'country_Guam', 'country_Guatemala', 'country_Haiti', 'country_Honduras', 'country_Hong Kong', 'country_Hungary', 'country_Iceland', 'country_India', 'country_Indonesia', 'country_Iran (ISLAMIC Republic Of)', 'country_Iraq', 'country_Ireland', 'country_Israel', 'country_Italy', 'country_Jamaica', 'country_Japan', 'country_Jordan', 'country_Kazakhstan', 'country_Kenya', 'country_Korea Republic of', 'country_Kuwait', 'country_Kyrgyzstan', \"country_Lao People's Democratic Republic\", 'country_Latvia', 'country_Lebanon', 'country_Lesotho', 'country_Libyan Arab Jamahiriya', 'country_Liechtenstein', 'country_Lithuania', 'country_Luxembourg', 'country_Macau', 'country_Macedonia', 'country_Madagascar', 'country_Malawi', 'country_Malaysia', 'country_Maldives', 'country_Malta', 'country_Mauritius', 'country_Mexico', 'country_Moldova Republic of', 'country_Monaco', 'country_Mongolia', 'country_Montenegro', 'country_Morocco', 'country_Mozambique', 'country_Myanmar', 'country_Namibia', 'country_Nauru', 'country_Nepal', 'country_Netherlands', 'country_New Caledonia', 'country_New Zealand', 'country_Nicaragua', 'country_Niger', 'country_Nigeria', 'country_Norway', 'country_Oman', 'country_Pakistan', 'country_Palestinian Territory Occupied', 'country_Panama', 'country_Papua New Guinea', 'country_Paraguay', 'country_Peru', 'country_Philippines', 'country_Poland', 'country_Portugal', 'country_Puerto Rico', 'country_Qatar', 'country_Reunion', 'country_Romania', 'country_Russian Federation', 'country_Rwanda', 'country_Saint Kitts and Nevis', 'country_Saint Martin', 'country_San Marino', 'country_Saudi Arabia', 'country_Senegal', 'country_Serbia', 'country_Seychelles', 'country_Singapore', 'country_Slovakia (SLOVAK Republic)', 'country_Slovenia', 'country_South Africa', 'country_South Sudan', 'country_Spain', 'country_Sri Lanka', 'country_Sudan', 'country_Sweden', 'country_Switzerland', 'country_Syrian Arab Republic', 'country_Taiwan; Republic of China (ROC)', 'country_Tajikistan', 'country_Tanzania United Republic of', 'country_Thailand', 'country_Trinidad and Tobago', 'country_Tunisia', 'country_Turkey', 'country_Turkmenistan', 'country_Uganda', 'country_Ukraine', 'country_United Arab Emirates', 'country_United Kingdom', 'country_United States', 'country_Uruguay', 'country_Uzbekistan', 'country_Vanuatu', 'country_Venezuela', 'country_Viet Nam', 'country_Virgin Islands (U.S.)', 'country_Yemen', 'country_Zambia', 'country_Zimbabwe']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. Identify numeric and categorical columns\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"Numeric columns: {numeric_cols}\")\n",
    "print(f\"Categorical columns: {categorical_cols}\")\n",
    "# 5. Create preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5d51d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Create preprocessing pipeline\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "382674b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated PR-AUC: 0.0957 (+/- 0.0027)\n"
     ]
    }
   ],
   "source": [
    "# Create a mask for non-NaN values\n",
    "mask = ~y_train.isna()\n",
    "\n",
    "# Apply the mask to both X and y\n",
    "X_train_clean = X_train[mask]\n",
    "y_train_clean = y_train[mask].astype(int)  # Convert to int for classification\n",
    "\n",
    "# Now run cross-validation on the cleaned data\n",
    "cv_scores = cross_val_score(\n",
    "    lr_pipeline, \n",
    "    X_train_clean, \n",
    "    y_train_clean, \n",
    "    cv=cv, \n",
    "    scoring='average_precision',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"Cross-validated PR-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3f66dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Data Splitting ===\n",
      "Error during train-test split: name 'train_test_split' is not defined\n",
      "\n",
      "Trying without stratification...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m(\n\u001b[32m      5\u001b[39m         X, y, test_size=\u001b[32m0.2\u001b[39m, stratify=y, random_state=RANDOM_STATE\n\u001b[32m      6\u001b[39m     )\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mData split successfully\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_test_split' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError during train-test split: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTrying without stratification...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m X_train, X_test, y_train, y_test = \u001b[43mtrain_test_split\u001b[49m(\n\u001b[32m     15\u001b[39m     X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=RANDOM_STATE\n\u001b[32m     16\u001b[39m )\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mData split successfully (without stratification)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Test set size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_test.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# 7. Data Splitting\n",
    "print(\"\\n=== Data Splitting ===\")\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    "    )\n",
    "    print(\"Data split successfully\")\n",
    "    print(f\"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n",
    "    print(f\"Fraud rate in training: {y_train.mean():.4f}\")\n",
    "    print(f\"Fraud rate in test: {y_test.mean():.4f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during train-test split: {e}\")\n",
    "    print(\"\\nTrying without stratification...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_STATE\n",
    "    )\n",
    "    print(\"Data split successfully (without stratification)\")\n",
    "    print(f\"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n",
    "    print(f\"Fraud rate in training: {y_train.mean():.4f}\")\n",
    "    print(f\"Fraud rate in test: {y_test.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53e70697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Model Pipeline\n",
    "def create_model_pipeline(estimator):\n",
    "    return Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', estimator)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d15472ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in y_train: 2062\n"
     ]
    }
   ],
   "source": [
    "print(\"NaN values in y_train:\", y_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbf4b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training Logistic Regression ===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Cross-validation\u001b[39;00m\n\u001b[32m     10\u001b[39m cv = StratifiedKFold(n_splits=\u001b[32m5\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m, random_state=RANDOM_STATE)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m cv_scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr_pipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maverage_precision\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCross-validated PR-AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores.mean()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (+/- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcv_scores.std()*\u001b[32m2\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\KAIM\\weak-5\\fraud-detection\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\KAIM\\weak-5\\fraud-detection\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:651\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    648\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    649\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    660\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    661\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    662\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\KAIM\\weak-5\\fraud-detection\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\KAIM\\weak-5\\fraud-detection\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:365\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    362\u001b[39m     routed_params.estimator = Bunch(fit=params)\n\u001b[32m    363\u001b[39m     routed_params.scorer = Bunch(score={})\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m indices = \u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_indices:\n\u001b[32m    367\u001b[39m     \u001b[38;5;66;03m# materialize the indices since we need to store them in the returned dict\u001b[39;00m\n\u001b[32m    368\u001b[39m     indices = \u001b[38;5;28mlist\u001b[39m(indices)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\KAIM\\weak-5\\fraud-detection\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:889\u001b[39m, in \u001b[36mStratifiedKFold.split\u001b[39m\u001b[34m(self, X, y, groups)\u001b[39m\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m groups \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    885\u001b[39m     warnings.warn(\n\u001b[32m    886\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe groups parameter is ignored by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    887\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    888\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m889\u001b[39m y = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().split(X, y, groups)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\KAIM\\weak-5\\fraud-detection\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1069\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1070\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1071\u001b[39m     )\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1074\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1076\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1078\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1082\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1083\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\KAIM\\weak-5\\fraud-detection\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:133\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    131\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    138\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\KAIM\\weak-5\\fraud-detection\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:182\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    168\u001b[39m     msg_err += (\n\u001b[32m    169\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    170\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    180\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    181\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input y contains NaN."
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Training Logistic Regression ===\")\n",
    "lr_pipeline = create_model_pipeline(\n",
    "    LogisticRegression(\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE,\n",
    "        max_iter=1000\n",
    "    )\n",
    ")\n",
    "# Cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_scores = cross_val_score(\n",
    "    lr_pipeline, X_train, y_train, \n",
    "    cv=cv, \n",
    "    scoring='average_precision',\n",
    "    n_jobs=-1\n",
    ")\n",
    "print(f\"Cross-validated PR-AUC: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
